{
  "face_motion_tracker/src/main.py": "from face_tracker import FaceTracker\nfrom motion_detector import MotionDetector\nimport cv2\n\ndef main():\n    # Initialize video capture\n    cap = cv2.VideoCapture(0)\n\n    # Initialize face tracker and motion detector\n    face_tracker = FaceTracker()\n    motion_detector = MotionDetector()\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Detect faces\n        faces = face_tracker.detect_faces(frame)\n        for (x, y, w, h) in faces:\n            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n\n        # Detect motion\n        motion = motion_detector.detect_motion(frame)\n        if motion:\n            cv2.putText(frame, 'Motion Detected', (10, 30),\n                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n\n        # Display the resulting frame\n        cv2.imshow('Face and Motion Tracker', frame)\n\n        # Break loop on 'q' key press\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n\n    # Release resources\n    cap.release()\n    cv2.destroyAllWindows()\n\nif __name__ == \"__main__\":\n    main()",
  "face_motion_tracker/src/face_tracker.py": "import cv2\n\nclass FaceTracker:\n    def __init__(self):\n        # Load the pre-trained Haar cascade classifier for face detection\n        self.face_cascade = cv2.CascadeClassifier(\n            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\n    def detect_faces(self, frame):\n        # Convert the frame to grayscale as the face detector expects gray images\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n        # Detect faces in the image\n        faces = self.face_cascade.detectMultiScale(\n            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n\n        return faces",
  "face_motion_tracker/src/motion_detector.py": "import cv2\n\nclass MotionDetector:\n    def __init__(self):\n        self.first_frame = None\n\n    def detect_motion(self, frame):\n        # Convert frame to grayscale and apply Gaussian blur\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n\n        # Initialize the first frame\n        if self.first_frame is None:\n            self.first_frame = gray\n            return False\n\n        # Compute absolute difference between the first frame and current frame\n        frame_delta = cv2.absdiff(self.first_frame, gray)\n        thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n\n        # Dilate the threshold image to fill in holes\n        thresh = cv2.dilate(thresh, None, iterations=2)\n\n        # Find contours on thresholded image\n        contours, _ = cv2.findContours(\n            thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Check if any contours are large enough to be considered motion\n        for contour in contours:\n            if cv2.contourArea(contour) > 500:\n                return True\n        return False",
  "face_motion_tracker/src/utils.py": "# Placeholder for utility functions if needed\ndef helper_function():\n    pass",
  "setup.py": "from setuptools import setup, find_packages\n\nsetup(\n    name='face-motion-tracker',\n    version='0.1.0',\n    packages=find_packages(),\n    install_requires=[\n        'opencv-python',\n    ],\n    entry_points={\n        'console_scripts': [\n            'face-motion-tracker=src.main:main',\n        ],\n    },\n    author='Akeem Sulaimon & ChatGPT',\n    author_email='your.email@example.com',\n    description='A Python application for face tracking and motion detection using OpenCV.',\n    url='https://github.com/sulaimonao/face-motion-tracker',\n)",
  "requirements.txt": "opencv-python",
  "README.md": "# Face Motion Tracker\n\nA Python application that captures live video input from your computer's camera to track faces and detect motion using OpenCV.\n\n## Features\n\n- Real-time face detection.\n- Real-time motion detection.\n- Simple and easy-to-use interface.\n\n## Installation\n\n```bash\ngit clone https://github.com/yourusername/face-motion-tracker.git\ncd face-motion_tracker\npython setup.py install\n```\n\n## Usage\n\nActivate the virtual environment if you have one:\n\n```bash\nsource venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n```\n\nRun the application:\n\n```bash\nface-motion-tracker\n```\n\nPress **'q'** to exit the application.\n\n## Requirements\n\n- Python 3.x\n- OpenCV\n\n## License\n\nThis project is licensed under the MIT License.",
  ".gitignore": "__pycache__/\n.env\nvenv/"
}
